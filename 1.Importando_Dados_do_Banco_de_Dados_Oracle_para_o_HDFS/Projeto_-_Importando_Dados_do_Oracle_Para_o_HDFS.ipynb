{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72ccc779",
   "metadata": {},
   "source": [
    "# <center><span style=\"font-size: 42px;color: darkgreen;\">Projeto - Importando Dados do Banco de Dados Oracle Para o HDFS</center></span>\n",
    "\n",
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Contexto\n",
    "\n",
    "<br>\n",
    "\n",
    "A **Oracle** é líder mundial em banco de dados e uma das gigantes da tecnologia. Seus bancos de dados são amplamente utilizados em Data Warehouses ou sistemas ERP, como **SAP**, **PeopleSoft** e **JD Edwards**. Esses sistemas frequentemente armazenam milhões de registros, tornando essencial o uso de soluções eficientes para manipulação e análise desses dados.\n",
    "\n",
    "Neste projeto, apresentaremos, passo a passo, como importar dados do banco de dados Oracle para o HDFS utilizando o **Sqoop**, uma ferramenta **ETL gratuita** e parte integrante do ecossistema Hadoop. O **Sqoop** permite a conexão via **JDBC** ao banco de dados Oracle, a execução de queries, a extração de dados e o carregamento no **HDFS**, possibilitando posterior processamento analítico em um cluster.\n",
    "\n",
    "O projeto será realizado em uma **Máquina Virtual (VM)**, configurada no **Oracle VirtualBox**, com todos os componentes necessários, incluindo Hadoop, Sqoop e banco de dados Oracle.  \n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Problema de Negócio\n",
    "\n",
    "<br>\n",
    "\n",
    "> Como mover dados de um banco de dados Oracle para o HDFS de maneira eficiente, utilizando ferramentas do ecossistema Hadoop?\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "# Sobre o Dataset\n",
    "\n",
    "<br>\n",
    "\n",
    "Para este projeto, utilizaremos um dataset contendo informações de empresas globais. O arquivo, chamado **`companies_sorted.csv`**, possui milhões de registros e um tamanho total de aproximadamente 1GB. O objetivo é explorar as ferramentas para mover os dados do banco de dados **Oracle**, onde serão carregados, para o **HDFS**.\n",
    "\n",
    "<br>\n",
    "\n",
    "### **Descrição do Dataset**\n",
    "\n",
    "O dataset contém as seguintes colunas:\n",
    "\n",
    "| **Coluna**                 | **Descrição**                                                             | **Tipo**     |\n",
    "|----------------------------|---------------------------------------------------------------------------|--------------|\n",
    "| `Unnamed: 0`               | Identificador único da entrada.                                           | int64        |\n",
    "| `name`                     | Nome da empresa.                                                         | object       |\n",
    "| `domain`                   | Domínio ou URL da empresa.                                               | object       |\n",
    "| `year founded`             | Ano de fundação da empresa.                                              | float64      |\n",
    "| `industry`                 | Setor da indústria a que a empresa pertence.                             | object       |\n",
    "| `size range`               | Faixa de tamanho da empresa (ex.: 10001+).                               | object       |\n",
    "| `locality`                 | Localidade, incluindo cidade e estado.                                   | object       |\n",
    "| `country`                  | País de operação.                                                        | object       |\n",
    "| `linkedin url`             | URL do perfil da empresa no LinkedIn.                                    | object       |\n",
    "| `current employee estimate`| Estimativa atual de funcionários da empresa.                             | int64        |\n",
    "| `total employee estimate`  | Estimativa total de funcionários ao longo do tempo.                      | int64        |\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Alternando Entre Usuários\n",
    "\n",
    "- **Conectar como usuário root**: `su` (digitar senha)\n",
    "- **Digitar**: `su - nome_usuario`\n",
    "\n",
    "<br><br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7afac7",
   "metadata": {},
   "source": [
    "# <center><u><span style=\"font-size: 34px;color: darkgreen;\">Início do Projeto</span></center></u>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "# 1. Iniciando os Serviços\n",
    "\n",
    "<br>\n",
    "\n",
    "Ná **máquina virtual** executar os comandos abaixo:\n",
    "\n",
    "<br>\n",
    "\n",
    "- **1.1 Iniciar o Listener digitando no terminal**:\n",
    "   ```java\n",
    "   lsnrctl start  |  lsnrctl stop\n",
    "   ```\n",
    "- **1.2 Iniciar o Banco de Dados digitando no terminal**:\n",
    "   ```java\n",
    "   sqlplus / as sysdba\n",
    "   ```\n",
    "- **1.3 Dentro do terminal do Oracle, digitar**:\n",
    "   ```java\n",
    "   startup  |  shutdown immediate\n",
    "   ```\n",
    "- **1.4 Verificar Status**:\n",
    "   ```java\n",
    "   lsnrctl status\n",
    "   ```\n",
    "   \n",
    "<br><br><br>\n",
    "\n",
    "# 2. Carregando Dados Para o Banco Oracle\n",
    "\n",
    "<br>\n",
    "\n",
    "### 2.1 Criando Um Schema (se desejar criar um Schema novo ou usar *curso*)\n",
    "\n",
    "<br>\n",
    "\n",
    "A seção **2.1 Criando Um Schema** é **opcional** e deve ser seguida apenas se você desejar criar um **novo schema**. Caso o schema `curso` já exista no banco de dados, você pode pular diretamente para a **seção 2.2 Conectando com o Schema `curso`**, onde é detalhado como se conectar e utilizar o schema existente.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.1.1 Acessar Terminal do sqlplus**:\n",
    "   ```java\n",
    "   sqlplus / as sysdba\n",
    "   ```\n",
    "- **2.1.2  Criando o schema (usuário) `curso`**:\n",
    "   ```java\n",
    "   create user curso identified by digitar_senha;\n",
    "   ```\n",
    "- **2.1.3 Conceder previlégios necessários para `curso`**:\n",
    "   ```java\n",
    "   grant connect, resource, unlimited tablespace to curso;\n",
    "   ```\n",
    "- **2.1.4 Sair do terminal do sqlplus**:\n",
    "   ```java\n",
    "   exit\n",
    "   ```\n",
    "   \n",
    "<br><br>\n",
    "\n",
    "### 2.2 Conectando com o Schema `curso`\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.2.1 Acessar Terminal do sqlplus como `curso` (digitar senha)**:\n",
    "   ```bash\n",
    "   sqlplus curso@orcl\n",
    "   ```\n",
    "   \n",
    "<br><br>\n",
    "\n",
    "### 2.3 Criando uma Tabela\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.3.1 Acessar Terminal do sqlplus como `curso` e digitar**:\n",
    "   ```sql\n",
    "CREATE TABLE companies (ID NUMBER PRIMARY KEY, NAME VARCHAR2(500), DOMAIN VARCHAR2(255), YEAR_FOUNDED VARCHAR2(30), INDUSTRY VARCHAR2(255), SIZE_RANGE VARCHAR2(50), LOCALITY VARCHAR2(255), COUNTRY VARCHAR2(100), LINKEDIN_URL VARCHAR2(800), CURRENT_EMPLOYEE_ESTIMATE VARCHAR2(100), TOTAL_EMPLOYEE_ESTIMATE VARCHAR2(255));\n",
    "\n",
    "   SELECT table_name FROM user_tables;\n",
    "   ```\n",
    "   \n",
    "<br><br>\n",
    "\n",
    "### 2.4 Preparando a Carga de Dados\n",
    "\n",
    "<br>\n",
    "\n",
    "#### 2.4.1 Realizando `Limpeza`nos dados antes de enviar para o banco oracle e `salvando`:\n",
    "\n",
    "<br>\n",
    "\n",
    "```python\n",
    "# Carregar o arquivo em duas partes\n",
    "import pandas as pd\n",
    "\n",
    "filename = \"Dataset/combined_companies_dataset.csv\"\n",
    "\n",
    "# Verificar o número de linhas no arquivo\n",
    "num_lines = sum(1 for line in open(filename))\n",
    "print(f\"O arquivo tem {num_lines} linhas.\")\n",
    "\n",
    "# Carregar a primeira metade\n",
    "first_half = pd.read_csv(filename, nrows=num_lines // 2)\n",
    "print(f\"\\nPrimeira parte carregada com {len(first_half)} linhas.\\n\\n\\n\")\n",
    "\n",
    "# Carregar a segunda metade\n",
    "second_half = pd.read_csv(\n",
    "    filename,\n",
    "    skiprows=(num_lines // 2 + 1),  # Ignorar o cabeçalho extra\n",
    "    names=first_half.columns,  # Reutilizar os nomes das colunas da primeira parte\n",
    "    header=None  # Indicar que não há cabeçalho no que será carregado\n",
    ")\n",
    "print(f\"\\nSegunda parte carregada com {len(second_half)} linhas.\")\n",
    "\n",
    "# Converter para o tipo Int64, que permite valores NaN\n",
    "first_half['year_founded'] = first_half['year_founded'].astype('Int64')\n",
    "second_half['year_founded'] = second_half['year_founded'].astype('Int64')\n",
    "\n",
    "# Remover aspas apenas nas colunas de texto\n",
    "text_columns = first_half.select_dtypes(include=['object']).columns\n",
    "first_half[text_columns] = first_half[text_columns].applymap(lambda x: x.replace('\"', '') if isinstance(x, str) else x)\n",
    "text_columns = second_half.select_dtypes(include=['object']).columns\n",
    "second_half[text_columns] = second_half[text_columns].applymap(lambda x: x.replace('\"', '') if isinstance(x, str) else x)\n",
    "\n",
    "# Substituir vírgulas por espaço e hífen apenas nas colunas de texto\n",
    "text_columns = first_half.select_dtypes(include=['object']).columns\n",
    "first_half[text_columns] = first_half[text_columns].applymap(lambda x: x.replace(',', ' -') if isinstance(x, str) else x)\n",
    "text_columns = second_half.select_dtypes(include=['object']).columns\n",
    "second_half[text_columns] = second_half[text_columns].applymap(lambda x: x.replace(',', ' -') if isinstance(x, str) else x)\n",
    "\n",
    "# Excluir a primeira coluna\n",
    "first_half = first_half.drop(columns=first_half.columns[0])\n",
    "second_half = second_half.drop(columns=second_half.columns[0])\n",
    "\n",
    "# Salvar o arquivo com vírgula como separador\n",
    "first_half.to_csv(\"Dataset/campanies_first_half_no_header.csv\", index=False, header=False, sep=\",\")\n",
    "print('\\nArquivo first_half salvo.')\n",
    "\n",
    "second_half.to_csv(\"Dataset/campanies_second_half_no_header.csv\", index=False, header=False, sep=\",\")\n",
    "print('\\nArquivo second_half salvo.')\n",
    "```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Para carregar dados no **Oracle**, usamos o **SQL*Loader**. Este aplicativo requer um **control file**:\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.4.2 Navegar até diretório *home* criar um novo diretório chamado `etl`**:\n",
    "   ```bash\n",
    "   mkdir etl\n",
    "   ```\n",
    "- **2.4.3 Dentro do diretório `etl` criar o arquivo `loader.dat` digitando no terminal**:\n",
    "   ```bash\n",
    "   gedit loader.dat\n",
    "   ```\n",
    "- **2.4.4 No arquivo `loader.dat` colar o conteúdo e salvar**:\n",
    "   ```data\n",
    "load data\n",
    "INFILE '/home/oracle/Documents/Datasets/campanies_first_half_no_header.csv'\n",
    "INTO TABLE companies\n",
    "APPEND\n",
    "FIELDS TERMINATED BY ','\n",
    "trailing nullcols\n",
    "(id SEQUENCE (MAX,1),\n",
    "name CHAR(255),\n",
    "domain CHAR(255),\n",
    "year_founded CHAR(6),\n",
    "industry CHAR(255),\n",
    "size_range CHAR(50),\n",
    "locality CHAR(255),\n",
    "country CHAR(100),\n",
    "linkedin_url CHAR(255),\n",
    "current_employee_estimate CHAR(20),\n",
    "total_employee_estimate CHAR(20))\n",
    "   ```\n",
    "   \n",
    "- **2.4.5: Executando o arquivo `loader.dat` no terminal do diretório `etl`**:\n",
    "   ```bash\n",
    "   sqlldr userid=curso/digitar_senha control=loader.dat log=loader.log\n",
    "   ```\n",
    "- **2.4.6 Verificar Arquivo de Log**:\n",
    "   ```bash\n",
    "   gedit loader.log\n",
    "   ```\n",
    "   \n",
    "<br><br>\n",
    "\n",
    "\n",
    "### 2.5 Verificando Dados Carregados no Banco Oracle\n",
    "\n",
    "<br>\n",
    "\n",
    "- **2.5.1 Acessar Terminal do sqlplus como `curso` (digitar senha) ou outro schema/usuário**:\n",
    "   ```bash\n",
    "   sqlplus curso@orcl\n",
    "   ```\n",
    "- **2.5.2 Verificando tabelas no schema `curso`**:\n",
    "   ```bash\n",
    "   select table_name FROM user_tables;\n",
    "   ```\n",
    "- **2.5.3 Visualizando *count* (*quantidade*) de linhas da tabela `cinema`**:\n",
    "   ```bash\n",
    "   select count(*) from companies;\n",
    "   ```\n",
    "- **2.5.4 Visualizando as 5 primeiras linhas da tabela `cinema`**:\n",
    "   ```bash\n",
    "   SELECT * FROM companies WHERE ROWNUM <= 5;\n",
    "   ```   \n",
    "- **2.5.5 Visualizando 5 linhas aleatórias da tabela `cinema`**:\n",
    "   ```bash\n",
    "   SELECT * FROM companies ORDER BY dbms_random.value FETCH FIRST 5 ROWS ONLY;\n",
    "   ```\n",
    "- **2.5.6 Ajustando a exibição temporária para melhor visualizar**:\n",
    "   ```bash\n",
    "   SET LINESIZE 100\n",
    "   SET PAGESIZE 20\n",
    "   ```  \n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "# 3. Configurando o Sistema Para Importação de Dados do Banco de Dados Oracle para o HDFS com o Apache Sqoop\n",
    "\n",
    "<br>\n",
    "\n",
    "## 3.1 Iniciando os Serviços\n",
    "\n",
    "<br>\n",
    "\n",
    "####  <u>Hadoop</u>\n",
    "\n",
    "> **<u>Importante</u>**: é necessário está logado com o usuário **hadoop** para inicializar os **serviços do hadoop**.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.1.1 Iniciar o HDFS (NameNode, DataNode, SecondaryNameNode)**:\n",
    "   ```bash\n",
    "   start-dfs.sh  |  stop-dfs.sh\n",
    "   ```\n",
    "- **3.1.2 Iniciar o YARN (ResourceManager, NodeManager)**:\n",
    "   ```bash\n",
    "   start-yarn.sh  |  stop-yarn.sh\n",
    "   ```\n",
    "- **3.1.3 Verificando serviços**:\n",
    "   ```bash\n",
    "   jps\n",
    "   ```\n",
    "\n",
    "<br>\n",
    "\n",
    "#### <u>Oracle</u>\n",
    "\n",
    "> **<u>Importante</u>**: é necessário está logado com o usuário **oracle** para inicializar o **banco oracle**.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.1.4 Iniciar o Listener digitando no terminal**:\n",
    "   ```java\n",
    "   lsnrctl start  |  lsnrctl stop\n",
    "   ```\n",
    "- **3.1.5 Iniciar o Banco de Dados digitando no terminal**:\n",
    "   ```java\n",
    "   sqlplus / as sysdba\n",
    "   ```\n",
    "- **3.1.6 Dentro do terminal do Oracle, digitar**:\n",
    "   ```java\n",
    "   startup  |  shutdown immediate  |  exit\n",
    "   ```\n",
    "- **3.1.7 Verificar Status**:\n",
    "   ```java\n",
    "   lsnrctl status\n",
    "   ```\n",
    "- **3.1.8 Acessar Terminal do sqlplus como `curso` (digitar senha) ou outro schema/usuário**:\n",
    "   ```bash\n",
    "   sqlplus curso@orcl\n",
    "   ```\n",
    "- **3.1.9 Verificando tabelas no schema `curso`** (iremos usar a tabela **companies_hadoop** que foi clonada a partir da tabela **companies**):\n",
    "   ```bash\n",
    "   select table_name FROM user_tables;\n",
    "   ```\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 3.2 Configurando o Driver JDBC\n",
    "\n",
    "<br>\n",
    "\n",
    "O `Apache Sqoop` conecta-se ao `Banco Oracle` usando o **driver JDBC**.\n",
    "\n",
    "Cada **banco relacional** possui seu próprio **driver JDBC**, como o `MySQL` e o `PostgreSQL`. \n",
    "\n",
    "No caso do` Oracle`, é necessário fazer o **download do driver JDBC** específico diretamente no site da Oracle:\n",
    "\n",
    "https://www.oracle.com/database/technologies/jdbc-ucp-122-downloads.html\n",
    "\n",
    "Após o download, acesse a pasta onde o arquivo foi descompactado, localize o `ojdbc8.jar` e mova-o para o diretório do `Sqoop`, permitindo que o `Sqoop` reconheça o **driver JDBC**. O procedimento para drivers de outros bancos é o mesmo. No terminal digite:\n",
    "\n",
    "- Conectar como usuário root: `su` (depois digite a senha)\n",
    "- Como usuário root copie o arquivo com: `cp ojdbc8.jar /opt/sqoop/lib`\n",
    "- Acessar diretório do sqoop: `cd /opt/sqoop/lib/`\n",
    "- Alterar propriedade do arquivo ojdbc8.jar: `chown hadoop:hadoop ojdbc8.jar`\n",
    "- Alterar a propriedade do arquivo commons-lang-2.6.jar: `chown hadoop:hadoop commons-lang-2.6.jar`\n",
    "- Sair do usuário root: `exit`\n",
    "\n",
    "<br><br>\n",
    "\n",
    "## 3.3 Ajustando os Previlégios de Acesso\n",
    "\n",
    "<br>\n",
    "\n",
    "Em um **Ambiente de Produção** em empresas de médio e grande porte, cada *software* normalmente é executado em um servidor separado. Por exemplo:\n",
    "\n",
    "- Um servidor é dedicado ao `Banco Oracle`,\n",
    "- Outro servidor é dedicado ao `Apache Sqoop`,\n",
    "- E uma máquina ou um grupo de máquinas são dedicadas ao `Apache HDFS`.\n",
    "\n",
    "Neste laboratório, configuramos um **Ambiente de Teste** em uma única máquina. Nessa configuração, todos os serviços estão instalados, mas distribuídos em **diferentes usuários** no mesmo sistema operacional. Essa configuração gera desafios, pois cada serviço possui seu próprio usuário.\n",
    "\n",
    "Dentro deste cenário, o **usuário oracle**, que executa o `Banco Oracle`, atualmente não possui acesso ao `HDFS`, pois ele está instalado no **usuário hadoop**. Para que o `Sqoop` possa acessar o `HDFS` e funcionar corretamente, é necessário **conceder acesso ao usuário oracle** para que ele consiga interagir com o `HDFS`.\n",
    "\n",
    "O **objetivo** é **ajustar os privilégios de acesso** de modo que os diferentes usuários no sistema possam interagir com os serviços necessários, permitindo o uso completo de todos os serviços em uma única máquina de teste.\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.3.1 No `usuario oracle`, configurar as variáveis de ambiente para o Hadoop e Sqoop**.\n",
    "  - Ir ao terminal e digitar: `gedit .bashrc`\n",
    "  - No arquivo .bashrch colar o conteúdo:\n",
    "   ```code\n",
    "    # Java JDK\n",
    "    export JAVA_HOME=/opt/jdk\n",
    "    export PATH=$PATH:$JAVA_HOME/bin\n",
    "    \n",
    "    # Hadoop\n",
    "    export HADOOP_HOME=/opt/hadoop\n",
    "    export HADOOP_INSTALL=$HADOOP_HOME\n",
    "    export HADOOP_COMMON_HOME=$HADOOP_HOME\n",
    "    export HADOOP_MAPRED_HOME=$HADOOP_HOME\n",
    "    export HADOOP_HDFS_HOME=$HADOOP_HOME\n",
    "    export YARN_HOME=$HADOOP_HOME\n",
    "    export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin\n",
    "    \n",
    "    # Sqoop\n",
    "    export SQOOP_HOME=/opt/sqoop\n",
    "    export PATH=$PATH:$SQOOP_HOME/bin\n",
    "    export HCAT_HOME=/opt/sqoop/hcatalog\n",
    "    export ACCUMULO_HOME=/opt/sqoop/accumulo\n",
    "   ```\n",
    "   \n",
    "   - Após salvar digite: `source .bashrc`\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.3.2 No `usuario hadoop`, definir os privilégios com os comandos abaixos**: \n",
    "\n",
    "```code\n",
    "    hdfs dfsadmin -safemode leave\n",
    "    hdfs dfs -chmod -R 777 /\n",
    "    chmod -R 777 /opt/hadoop/logs\n",
    "    exit\n",
    "```\n",
    "<br>\n",
    "\n",
    "- **3.3.3 No `usuario root`, definir os privilégios com os comandos abaixos**:\n",
    "\n",
    "```code\n",
    "    groups oracle\n",
    "    usermod -a -G hadoop oracle\n",
    "    groups oracle\n",
    "    exit\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **3.3.4 No `usuario oracle`, testar digitando no terminal**:\n",
    "\n",
    "```code\n",
    "    hdfs dfs -ls /\n",
    "```\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "# 4. Transferindo os Dados do Oracle para o HDFS com o Apache Sqoop\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.1 Não esquecer de logar como usuário `hadoop` e após iniciar o serviços digitar no terminal**:\n",
    "\n",
    "```code\n",
    "hdfs dfsadmin -safemode leave\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.2 No `usuario oracle`, acessar o diretório `etl` e digitar no terminal**:\n",
    "\n",
    "```code\n",
    "sqoop import --connect jdbc:oracle:thin:curso/0804@dataserver.localdomain:1539/orcl --username curso --password 0804 --query \"SELECT NAME, DOMAIN, YEAR_FOUNDED, INDUSTRY, SIZE_RANGE, LOCALITY, COUNTRY, LINKEDIN_URL, CURRENT_EMPLOYEE_ESTIMATE, TOTAL_EMPLOYEE_ESTIMATE FROM COMPANIES_HADOOP WHERE \\$CONDITIONS\" --target-dir /user/oracle/output --delete-target-dir -m 1\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.3 Checar se diretório `oracle` foi criado com**:\n",
    "\n",
    "```code\n",
    "hdfs dfs -ls /user\n",
    "hdfs dfs -ls /user/oracle\n",
    "hdfs dfs -ls /user/oracle/output\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.4 Visualizando conteúdo**:\n",
    "\n",
    "```code\n",
    "hdfs dfs -cat /user/oracle/output/part-m-00000\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.5 Verificando quantidade de linhas**:\n",
    "\n",
    "```code\n",
    "hdfs dfs -cat /user/oracle/output/part-m-00000 | wc -l\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.6 No diretório `etl` foi gerado o arquivo `QueryResult.java` que contém o código do MapReduce necessário para importação dos dados**:\n",
    "\n",
    "```code\n",
    "gedit QueryResult.java\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.7 Comando usado para corrigir problemas com blocos corrompidos, caso ocorra**:\n",
    "\n",
    "```code\n",
    "hdfs fsck / | egrep -v '^\\.+$' | grep -v replica | grep -v Replica\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "- **4.8 Para deixar o modo de segurança do Hadoop caso ocorrar algum problema** (tem que estar logado como usário hadoop):\n",
    "\n",
    "```code\n",
    "hdfs dfsadmin -safemode leave\n",
    "```\n",
    "\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78a7c44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49482207",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlldr userid=curso/digitar_senha control=loader.dat log=loader.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c5ada9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc5a109a",
   "metadata": {},
   "source": [
    "sqoop import --connect jdbc:oracle:thin:aluno/dsahadoop@dataserver.localdomain:1539/orcl --username aluno -password sua_senha --query \"select user_id, movie_id from cinema where rating = 1 and \\$CONDITIONS\" --target-dir /user/oracle/output -m 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e690bf1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e64c4fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d02add5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0739d5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08eed958",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ad1012",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf74f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fb10bcb",
   "metadata": {},
   "source": [
    "sqoop import --connect jdbc:oracle:thin:curso/0804@dataserver.localdomain:1539/orcl --username curso --password 0804 --query \"SELECT ID, NAME, DOMAIN, YEAR_FOUNDED, INDUSTRY, SIZE_RANGE, LOCALITY, COUNTRY, LINKEDIN_URL, CURRENT_EMPLOYEE_ESTIMATE, TOTAL_EMPLOYEE_ESTIMATE FROM COMPANIES WHERE \\$CONDITIONS\" --target-dir /user/oracle/output/companies_data --delete-target-dir --fields-terminated-by ',' --lines-terminated-by '\\n' --null-string '\\\\N' --null-non-string '\\\\N' -m 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sqoop import --connect jdbc:oracle:thin:aluno/dsahadoop@dataserver.localdomain:1539/orcl --username aluno -password sua_senha --query \"select user_id, movie_id from cinema where rating = 1 and \\$CONDITIONS\" --target-dir /user/oracle/output -m 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e88f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqoop eval --connect jdbc:oracle:thin:@dataserver.localdomain:1539/orcl --username curso --password 0804 --query \"SELECT SYSDATE FROM DUAL;\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be95aa8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1041d060",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a950dcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab30c6aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f76ec8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b887afe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
